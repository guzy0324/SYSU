{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import graph_based_image_segmentation as gbis\n",
    "import json\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "sigma = 1\n",
    "k = 1\n",
    "k_i = 0\n",
    "total = list(range(1, 1001))\n",
    "for i in tqdm(range(1, 1001)):\n",
    "    src = cv2.imread('data/imgs/' + str(i) + '.png')\n",
    "    k, k_i, Id = gbis.Find_k(src.astype(float), k, k_i, sigma, gbis.MergeNeareast, gbis.Cosine)\n",
    "    if Id is not None:\n",
    "        vis = gbis.Visualize(Id)\n",
    "        cv2.imwrite('data/classification/segmentation/' + str(i) + '.png', vis.astype(float))\n",
    "    else:\n",
    "        total.remove(i)\n",
    "with open('data/classification/total.txt', 'w') as f:\n",
    "    f.write(str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/classification/total.txt') as f:\n",
    "    total = json.loads(f.readline())\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(total)\n",
    "train = total[:200]\n",
    "test = total[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 999/999 [05:50<00:00,  2.85it/s]\n"
     ]
    }
   ],
   "source": [
    "H = dict()\n",
    "for i in tqdm(total):\n",
    "    src = cv2.imread('data/imgs/' + str(i) + '.png')\n",
    "    h = [[0] * 512, list()]\n",
    "    Id = cv2.imread('data/classification/segmentation/' + str(i) + '.png')[:, :, 0].astype(np.uint)\n",
    "    Id_uni = np.unique(Id)\n",
    "    for j in Id_uni:\n",
    "        x2 = [0] * 512\n",
    "        for g, b, r in src[np.where(Id == j)]:\n",
    "            x2[g // 32 * 64 + b // 32 * 8 + r // 32] += 1\n",
    "            h[0][g // 32 * 64 + b // 32 * 8 + r // 32] += 1\n",
    "        h[1].append(x2)\n",
    "    H[str(i)] = h\n",
    "with open('data/classification/H.txt', 'w') as f:\n",
    "    f.write(json.dumps(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/classification/H.txt') as f:\n",
    "    H = json.loads(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = [list(), list()]\n",
    "for i in train:\n",
    "    for x in H[str(i)][1]:\n",
    "        X1[0].append(H[str(i)][0])\n",
    "        X1[1].append(x)\n",
    "X1[0] = np.array(X1[0])\n",
    "X1[1] = np.array(X1[1])\n",
    "X1 = np.concatenate([X1[i] / X1[i].sum(axis=1, keepdims=True) for i in (0, 1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 590 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/classification/pca.model']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pca = PCA(n_components=20).fit(X1)\n",
    "joblib.dump(pca, 'data/classification/pca.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = joblib.load('data/classification/pca.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pca.transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/classification/kmeans.model']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "k = 50\n",
    "kmeans = KMeans(n_clusters=k, init='k-means++', random_state=0).fit(X1)\n",
    "joblib.dump(kmeans, 'data/classification/kmeans.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = joblib.load('data/classification/kmeans.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X1 @ kmeans.cluster_centers_.T / (np.linalg.norm(X1) * np.linalg.norm(kmeans.cluster_centers_))\n",
    "X = np.concatenate((X1, X2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:05<00:00, 35.76it/s]\n"
     ]
    }
   ],
   "source": [
    "Y = list()\n",
    "for i in tqdm(train):\n",
    "    mask = cv2.imread('data/gt/' + str(i) + '.png')[:, :, 0] > 0\n",
    "    Id = cv2.imread('data/classification/segmentation/' + str(i) + '.png')[:, :, 0].astype(np.uint)\n",
    "    mask_new = gbis.Mask(mask, Id)[0][:, :, 0]\n",
    "    Id_uni = np.unique(Id)\n",
    "    for j in Id_uni:\n",
    "        Y.append(int(mask_new[Id == j].any()))\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(dataset, model_name):\n",
    "    X1 = [list(), list()]\n",
    "    for i in dataset:\n",
    "        for x in H[str(i)][1]:\n",
    "            X1[0].append(H[str(i)][0])\n",
    "            X1[1].append(x)\n",
    "    X1[0] = np.array(X1[0])\n",
    "    X1[1] = np.array(X1[1])\n",
    "    X1 = np.concatenate([X1[i] / X1[i].sum(axis=1, keepdims=True) for i in (0, 1)], axis=1)\n",
    "    X1 = pca.transform(X1)\n",
    "    X2 = X1 @ kmeans.cluster_centers_.T / (np.linalg.norm(X1) * np.linalg.norm(kmeans.cluster_centers_))\n",
    "    X = np.concatenate((X1, X2), axis=1)\n",
    "    model = joblib.load('data/classification/' + model_name + '.model')\n",
    "    Y_pred = model.predict(X)\n",
    "    Y = list()\n",
    "    for i in tqdm(dataset):\n",
    "        mask = cv2.imread('data/gt/' + str(i) + '.png')[:, :, 0] > 0\n",
    "        Id = cv2.imread('data/classification/segmentation/' + str(i) + '.png')[:, :, 0].astype(np.uint)\n",
    "        mask_new = gbis.Mask(mask, Id)[0][:, :, 0]\n",
    "        Id_uni = np.unique(Id)\n",
    "        for j in Id_uni:\n",
    "            Y.append(int(mask_new[Id == j].any()))\n",
    "    Y = np.array(Y)\n",
    "    TP = np.logical_and(Y == Y_pred, Y_pred != 0).sum()\n",
    "    FP = np.logical_and(Y != Y_pred, Y_pred != 0).sum()\n",
    "    FN = np.logical_and(Y == Y_pred, Y_pred == 0).sum()\n",
    "    TN = np.logical_and(Y != Y_pred, Y_pred == 0).sum()\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    print('Accuracy:', (Y == Y_pred).sum() / Y.shape[0])\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)\n",
    "    print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.13 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/classification/svc.model']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svc = SVC(random_state=0).fit(X, Y)\n",
    "joblib.dump(svc, 'data/classification/svc.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:05<00:00, 37.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8068181818181818\n",
      "Precision: 0.7926078028747433\n",
      "Recall: 0.1359154929577465\n",
      "F1 score: 0.2320408776675684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score(train, 'svc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 799/799 [00:21<00:00, 36.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7450807565867835\n",
      "Precision: 0.5934398654331371\n",
      "Recall: 0.11279854205966046\n",
      "F1 score: 0.18956531083767664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score(test, 'svc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 86.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/classification/lr.model']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(random_state=0).fit(X, Y)\n",
    "joblib.dump(lr, 'data/classification/lr.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:05<00:00, 34.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7247159090909091\n",
      "Precision: 0.4855072463768116\n",
      "Recall: 0.026264210113680908\n",
      "F1 score: 0.04983265154332465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score(train, 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 799/799 [00:22<00:00, 35.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7166611081995331\n",
      "Precision: 0.4733072916666667\n",
      "Recall: 0.024165669458848557\n",
      "F1 score: 0.04598355471220746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score(test, 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.49 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/classification/rfc.model']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rfc = RandomForestClassifier(random_state=0).fit(X, Y)\n",
    "joblib.dump(rfc, 'data/classification/rfc.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:05<00:00, 35.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9997159090909091\n",
      "Precision: 0.9989648033126294\n",
      "Recall: 0.2742256322818983\n",
      "F1 score: 0.4303232998885173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score(train, 'rfc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 799/799 [00:21<00:00, 36.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6865262756682071\n",
      "Precision: 0.45643314574034544\n",
      "Recall: 0.24483847461743988\n",
      "F1 score: 0.31871358236596053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score(test, 'rfc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
